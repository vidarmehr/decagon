{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ravanv/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixiedust database opened successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"margin:10px\">\n",
       "            <a href=\"https://github.com/ibm-watson-data-lab/pixiedust\" target=\"_new\">\n",
       "                <img src=\"https://github.com/ibm-watson-data-lab/pixiedust/raw/master/docs/_static/pd_icon32.png\" style=\"float:left;margin-right:10px\"/>\n",
       "            </a>\n",
       "            <span>Pixiedust version 1.1.14</span>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from operator import itemgetter\n",
    "from itertools import combinations\n",
    "import time\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "from sklearn import metrics\n",
    "\n",
    "import pixiedust\n",
    "from decagon.deep.optimizer import DecagonOptimizer\n",
    "from decagon.deep.model import DecagonModel\n",
    "from decagon.deep.minibatch import EdgeMinibatchIterator\n",
    "from decagon.utility import rank_metrics, preprocessing\n",
    "\n",
    "from polypharmacy.utility import *\n",
    "\n",
    "# Train on CPU (hide GPU) due to memory constraints\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"\"\n",
    "\n",
    "# Train on GPU\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = 'PCI_BUS_ID'\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "#config = tf.ConfigProto()\n",
    "#config.gpu_options.allow_growth = True\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "###########################################################\n",
    "#\n",
    "# Functions\n",
    "#\n",
    "###########################################################\n",
    "\n",
    "\n",
    "def get_accuracy_scores(edges_pos, edges_neg, edge_type):\n",
    "    feed_dict.update({placeholders['dropout']: 0})\n",
    "    feed_dict.update({placeholders['batch_edge_type_idx']: minibatch.edge_type2idx[edge_type]})\n",
    "    feed_dict.update({placeholders['batch_row_edge_type']: edge_type[0]})\n",
    "    feed_dict.update({placeholders['batch_col_edge_type']: edge_type[1]})\n",
    "    rec = sess.run(opt.predictions, feed_dict=feed_dict)\n",
    "\n",
    "    def sigmoid(x):\n",
    "        return 1. / (1 + np.exp(-x))\n",
    "\n",
    "    # Predict on test set of edges\n",
    "    preds = []\n",
    "    actual = []\n",
    "    predicted = []\n",
    "    edge_ind = 0\n",
    "    for u, v in edges_pos[edge_type[:2]][edge_type[2]]:\n",
    "        score = sigmoid(rec[u, v])\n",
    "        preds.append(score)\n",
    "        assert adj_mats_orig[edge_type[:2]][edge_type[2]][u,v] == 1, 'Problem 1'\n",
    "\n",
    "        actual.append(edge_ind)\n",
    "        predicted.append((score, edge_ind))\n",
    "        edge_ind += 1\n",
    "\n",
    "    preds_neg = []\n",
    "    for u, v in edges_neg[edge_type[:2]][edge_type[2]]:\n",
    "        score = sigmoid(rec[u, v])\n",
    "        preds_neg.append(score)\n",
    "        assert adj_mats_orig[edge_type[:2]][edge_type[2]][u,v] == 0, 'Problem 0'\n",
    "\n",
    "        predicted.append((score, edge_ind))\n",
    "        edge_ind += 1\n",
    "\n",
    "    preds_all = np.hstack([preds, preds_neg])\n",
    "    preds_all = np.nan_to_num(preds_all)\n",
    "    labels_all = np.hstack([np.ones(len(preds)), np.zeros(len(preds_neg))])\n",
    "    predicted = list(zip(*sorted(predicted, reverse=True, key=itemgetter(0))))[1]\n",
    "\n",
    "    roc_sc = metrics.roc_auc_score(labels_all, preds_all)\n",
    "    aupr_sc = metrics.average_precision_score(labels_all, preds_all)\n",
    "    apk_sc = rank_metrics.apk(actual, predicted, k=50)\n",
    "\n",
    "    return roc_sc, aupr_sc, apk_sc\n",
    "\n",
    "def construct_placeholders(edge_types):\n",
    "    placeholders = {\n",
    "        'batch': tf.placeholder(tf.int32, name='batch'),\n",
    "        'batch_edge_type_idx': tf.placeholder(tf.int32, shape=(), name='batch_edge_type_idx'),\n",
    "        'batch_row_edge_type': tf.placeholder(tf.int32, shape=(), name='batch_row_edge_type'),\n",
    "        'batch_col_edge_type': tf.placeholder(tf.int32, shape=(), name='batch_col_edge_type'),\n",
    "        'degrees': tf.placeholder(tf.int32),\n",
    "        'dropout': tf.placeholder_with_default(0., shape=()),\n",
    "    }\n",
    "    placeholders.update({\n",
    "        'adj_mats_%d,%d,%d' % (i, j, k): tf.sparse_placeholder(tf.float32)\n",
    "        for i, j in edge_types for k in range(edge_types[i,j])})\n",
    "    placeholders.update({\n",
    "        'feat_%d' % i: tf.sparse_placeholder(tf.float32)\n",
    "        for i, _ in edge_types})\n",
    "    return placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import networkx as nx\n",
    "\n",
    "# Returns dictionary from combination ID to pair of stitch IDs, \n",
    "# dictionary from combination ID to list of polypharmacy side effects, \n",
    "# and dictionary from side effects to their names.\n",
    "def load_combo_se(fname='bio-decagon-combo.csv'):\n",
    "    combo2stitch = {}\n",
    "    combo2se = defaultdict(set)\n",
    "    se2name = {}\n",
    "    fin = open(fname)\n",
    "    print ('Reading: %s' % fname)\n",
    "    fin.readline()\n",
    "    for line in fin:\n",
    "        stitch_id1, stitch_id2, se, se_name = line.strip().split(',')\n",
    "        combo = stitch_id1 + '_' + stitch_id2\n",
    "        combo2stitch[combo] = [stitch_id1, stitch_id2]\n",
    "        combo2se[combo].add(se)\n",
    "        se2name[se] = se_name\n",
    "    fin.close()\n",
    "    n_interactions = sum([len(v) for v in combo2se.values()])\n",
    "    print ('Drug combinations: %d Side effects: %d' % (len(combo2stitch), len(se2name)))\n",
    "    print ('Drug-drug interactions: %d' % (n_interactions))\n",
    "    return combo2stitch, combo2se, se2name\n",
    "\n",
    "# Returns networkx graph of the PPI network \n",
    "# and a dictionary that maps each gene ID to a number\n",
    "def load_ppi(fname='bio-decagon-ppi.csv'):\n",
    "    fin = open(fname)\n",
    "    print ('Reading: %s' % fname)\n",
    "    fin.readline()\n",
    "    edges = []\n",
    "    for line in fin:\n",
    "        gene_id1, gene_id2= line.strip().split(',')\n",
    "        edges += [[gene_id1,gene_id2]]\n",
    "    nodes = set([u for e in edges for u in e])\n",
    "    print ('Edges: %d' % len(edges))\n",
    "    print ('Nodes: %d' % len(nodes))\n",
    "    net = nx.Graph()\n",
    "    net.add_edges_from(edges)\n",
    "    net.remove_nodes_from(nx.isolates(net))\n",
    "    net.remove_edges_from(net.selfloop_edges())\n",
    "    node2idx = {node: i for i, node in enumerate(net.nodes())}\n",
    "    return net, node2idx\n",
    "\n",
    "# Does the same thing as load_ppi except that the nodes are all indicies starting from 0\n",
    "# Returns networkx graph of the PPI networkz \n",
    "# and a dictionary that maps each gene ID to a number\n",
    "def load_ppi_v2(fname='bio-decagon-ppi.csv'):\n",
    "    fin = open(fname)\n",
    "    print('Reading: %s' % fname)\n",
    "    fin.readline()\n",
    "    edges = []\n",
    "    ppi_to_idx = {}\n",
    "    idx = 0\n",
    "    for line in fin:\n",
    "        gene_id1, gene_id2= line.strip().split(',')\n",
    "        if gene_id1 not in ppi_to_idx:\n",
    "            ppi_to_idx[gene_id1] = idx\n",
    "            idx+=1\n",
    "        if gene_id2 not in ppi_to_idx:\n",
    "            ppi_to_idx[gene_id2] = idx\n",
    "            idx+=1\n",
    "        edges += [[ppi_to_idx[gene_id1],ppi_to_idx[gene_id2]]]\n",
    "    nodes = set([u for e in edges for u in e])\n",
    "    print( 'Edges: %d' % len(edges))\n",
    "    print( 'Nodes: %d' % len(nodes))\n",
    "    net = nx.Graph()\n",
    "    net.add_edges_from(edges)\n",
    "    net.remove_nodes_from(nx.isolates(net))\n",
    "    net.remove_edges_from(net.selfloop_edges())\n",
    "    return net, ppi_to_idx\n",
    "\n",
    "# Returns dictionary from Stitch ID to list of individual side effects, \n",
    "# and dictionary from side effects to their names.\n",
    "def load_mono_se(fname='bio-decagon-mono.csv'):\n",
    "    stitch2se = defaultdict(set)\n",
    "    se2name = {}\n",
    "    fin = open(fname)\n",
    "    print ('Reading: %s' % fname)\n",
    "    fin.readline()\n",
    "    for line in fin:\n",
    "        contents = line.strip().split(',')\n",
    "        stitch_id, se, = contents[:2]\n",
    "        se_name = ','.join(contents[2:])\n",
    "        stitch2se[stitch_id].add(se)\n",
    "        se2name[se] = se_name\n",
    "    return stitch2se, se2name\n",
    "\n",
    "# Returns dictionary from Stitch ID to list of drug targets\n",
    "def load_targets(fname='bio-decagon-targets.csv'):\n",
    "    stitch2proteins = defaultdict(set)\n",
    "    fin = open(fname)\n",
    "    print ('Reading: %s' % fname)\n",
    "    fin.readline()\n",
    "    for line in fin:\n",
    "        stitch_id, gene = line.strip().split(',')\n",
    "        stitch2proteins[stitch_id].add(gene)\n",
    "    return stitch2proteins\n",
    "\n",
    "# Returns dictionary from side effect to disease class of that side effect,\n",
    "# and dictionary from side effects to their names.\n",
    "def load_categories(fname='bio-decagon-effectcategories.csv'):\n",
    "    se2name = {}\n",
    "    se2class = {}\n",
    "    fin = open(fname)\n",
    "    print ('Reading: %s' % fname)\n",
    "    fin.readline()\n",
    "    for line in fin:\n",
    "    \tse, se_name, se_class = line.strip().split(',')\n",
    "    \tse2name[se] = se_name\n",
    "    \tse2class[se] = se_class\n",
    "    return se2class, se2name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: /Users/ravanv/Desktop/Decagon/data/bio-decagon-ppi.csv\n",
      "Edges: 715612\n",
      "Nodes: 19081\n",
      "Reading: /Users/ravanv/Desktop/Decagon/data/bio-decagon-targets.csv\n",
      "Reading: /Users/ravanv/Desktop/Decagon/data/bio-decagon-combo.csv\n",
      "Drug combinations: 63473 Side effects: 1317\n",
      "Drug-drug interactions: 4649441\n"
     ]
    }
   ],
   "source": [
    "#%%pixie_debugger -b load_ppi_v2\n",
    "###########################################################\n",
    "#\n",
    "# Load and preprocess data \n",
    "#\n",
    "###########################################################\n",
    "\n",
    "####\n",
    "# Attempt to load in datasets and uses them to train the model\n",
    "# \n",
    "# All preprocessed datasets used in the drug combination study are at: http://snap.stanford.edu/decagon:\n",
    "# (1) Download datasets from http://snap.stanford.edu/decagon to your local machine.\n",
    "# (2) Replace dummy toy datasets used here with the actual datasets you just downloaded.\n",
    "# (3) Train & test the model.\n",
    "####\n",
    "\n",
    "val_test_size = 0.10\n",
    "\n",
    "\n",
    "gene_net, node2idx = load_ppi_v2(\"/Users/ravanv/Desktop/Decagon/data/bio-decagon-ppi.csv\") # protein protein interactions\n",
    "stitch2proteins = load_targets(\"/Users/ravanv/Desktop/Decagon/data/bio-decagon-targets.csv\") #drug protein interations\n",
    "combo2stitch, combo2se, se2name = load_combo_se('/Users/ravanv/Desktop/Decagon/data/bio-decagon-combo.csv') #Drug drug interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# After running this, common_se holds a list of the side effects we're interested in predicting\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def get_se_counter(se_map):\n",
    "    side_effects = []\n",
    "    for drug in se_map:\n",
    "        side_effects += list(set(se_map[drug]))\n",
    "    return Counter(side_effects)\n",
    "\n",
    "combo_counter = get_se_counter(combo2se)\n",
    "\n",
    "common_se = []\n",
    "for se, count in combo_counter.most_common(964):\n",
    "    common_se += [se]\n",
    "common_se = set(common_se)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of side effects 964\n"
     ]
    }
   ],
   "source": [
    " #After running this cell, give each drug an unique integer ID. This will make it easier later to fill in the appropriate matricies\n",
    "# This mapping is stored in drug2idx\n",
    "\n",
    "# Each side effect is also given an unique integer ID. \n",
    "# This mapping is stored in se2idx\n",
    "\n",
    "# Proteins do not need to be given IDs, since the loader automatically generates such a unique id. \n",
    "\n",
    "drug2idx = {}\n",
    "idx = 0\n",
    "for combo, se_set in combo2se.items():     \n",
    "    if len(combo2se[combo].intersection(common_se)) == 0:\n",
    "        continue\n",
    "    drug_0 = combo.split(\"_\")[0]\n",
    "    drug_1 = combo.split(\"_\")[1]\n",
    "    if drug_0 not in drug2idx:\n",
    "        drug2idx[drug_0] = idx\n",
    "        idx+=1\n",
    "    if drug_1 not in drug2idx:\n",
    "        drug2idx[drug_1] = idx\n",
    "        idx+=1\n",
    "n_drugs = len(drug2idx)\n",
    "\n",
    "#count up all the unique side effects, give them a unique id\n",
    "idx = 0\n",
    "se2idx = {}\n",
    "for _, se_set in combo2se.items(): \n",
    "    for se in se_set:\n",
    "        if se not in se2idx and se in common_se:\n",
    "            se2idx[se] = idx\n",
    "            idx+=1\n",
    "        \n",
    "print(\"Number of side effects\", idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of drug-drug interactions 4576785\n"
     ]
    }
   ],
   "source": [
    "# Drug - drug interaction matrix\n",
    "# drug_drug_adj_list n matrixs. If drug_drug_adj_list[i][j][k] == 1, \n",
    "# then drug j interacts with drug k to cause side effect i\n",
    "\n",
    "drug_drug_adj_list = [np.zeros((n_drugs, n_drugs)) for _ in se2idx]\n",
    "\n",
    "count= 0\n",
    "for drug_drug, se_set in combo2se.items():\n",
    "    drug0 = drug_drug.split(\"_\")[0]\n",
    "    drug1 = drug_drug.split(\"_\")[1]\n",
    "    for se in se_set:\n",
    "        if drug0 in drug2idx and  drug1 in drug2idx and se in se2idx:\n",
    "            se_index = se2idx[se]\n",
    "            drug0_index = drug2idx[drug0]\n",
    "            drug1_index = drug2idx[drug1]\n",
    "            drug_drug_adj_list[se_index][drug0_index][drug1_index] = 1.        \n",
    "            drug_drug_adj_list[se_index][drug1_index][drug0_index] = 1.\n",
    "            count+=1\n",
    "        \n",
    "drug_drug_adj_list = [ sp.csr_matrix(item) for item in drug_drug_adj_list]\n",
    "drug_degrees_list = [np.array(drug_adj.sum(axis=0)).squeeze() for drug_adj in drug_drug_adj_list]\n",
    "        \n",
    "print(\"Number of drug-drug interactions\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of proteins 19081\n"
     ]
    }
   ],
   "source": [
    "# The loader protein loader was modified very slightly to ensure this works. See polypharmacy.utility.load_ppi_v2\n",
    "\n",
    "gene_adj = nx.adjacency_matrix(gene_net)\n",
    "gene_degrees = np.array(gene_adj.sum(axis=0)).squeeze()\n",
    "n_genes = gene_adj.shape[0]\n",
    "print(\"Number of proteins\", n_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to find 94 out of 18596 proteins (0.00505485050548505)\n",
      "Number of protein-drug edges 18596\n"
     ]
    }
   ],
   "source": [
    "# If gene_drug_matrix[i][j] == 1, then there is some interaction with protein i and drug j. \n",
    "\n",
    "missing = 0 \n",
    "present = 0\n",
    "gene_drug_matrix =  np.zeros((n_genes, n_drugs))\n",
    "for (drug_id, protein_set) in stitch2proteins.items():\n",
    "    drug_idx = drug2idx[drug_id]\n",
    "    for item in protein_set:\n",
    "        if item not in node2idx:\n",
    "            missing+=1\n",
    "        else:\n",
    "            protein_idx = node2idx[item]\n",
    "            gene_drug_matrix[protein_idx][drug_idx] = 1\n",
    "            present+=1\n",
    "print(\"Unable to find {} out of {} proteins ({})\".format(missing, present, missing/present))\n",
    "print(\"Number of protein-drug edges\", present)\n",
    "\n",
    "gene_drug_adj = sp.csr_matrix(gene_drug_matrix)\n",
    "drug_gene_adj = gene_drug_adj.transpose(copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19081, 645)\n"
     ]
    }
   ],
   "source": [
    "print(gene_drug_adj.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge types: 1932\n"
     ]
    }
   ],
   "source": [
    "# data representation\n",
    "adj_mats_orig = {\n",
    "    (0, 0): [gene_adj, gene_adj.transpose(copy=True)],\n",
    "    (0, 1): [gene_drug_adj],\n",
    "    (1, 0): [drug_gene_adj],\n",
    "    (1, 1): drug_drug_adj_list + [x.transpose(copy=True) for x in drug_drug_adj_list]\n",
    "}\n",
    "degrees = {\n",
    "    0: [gene_degrees, gene_degrees],\n",
    "    1: drug_degrees_list + drug_degrees_list\n",
    "}\n",
    "\n",
    "# featureless (genes)\n",
    "gene_feat = sp.identity(n_genes)\n",
    "gene_nonzero_feat, gene_num_feat = gene_feat.shape\n",
    "gene_feat = preprocessing.sparse_to_tuple(gene_feat.tocoo())\n",
    "\n",
    "# features (drugs)\n",
    "drug_feat = sp.identity(n_drugs)\n",
    "drug_nonzero_feat, drug_num_feat = drug_feat.shape\n",
    "drug_feat = preprocessing.sparse_to_tuple(drug_feat.tocoo())\n",
    "\n",
    "# data representation\n",
    "num_feat = {\n",
    "    0: gene_num_feat,\n",
    "    1: drug_num_feat,\n",
    "}\n",
    "nonzero_feat = {\n",
    "    0: gene_nonzero_feat,\n",
    "    1: drug_nonzero_feat,\n",
    "}\n",
    "feat = {\n",
    "    0: gene_feat,\n",
    "    1: drug_feat,\n",
    "}\n",
    "\n",
    "edge_type2dim = {k: [adj.shape for adj in adjs] for k, adjs in adj_mats_orig.items()}\n",
    "edge_type2decoder = {\n",
    "    (0, 0): 'bilinear',\n",
    "    (0, 1): 'bilinear',\n",
    "    (1, 0): 'bilinear',\n",
    "    (1, 1): 'dedicom',\n",
    "}\n",
    "\n",
    "edge_types = {k: len(v) for k, v in adj_mats_orig.items()}\n",
    "num_edge_types = sum(edge_types.values())\n",
    "print(\"Edge types:\", \"%d\" % num_edge_types)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining placeholders\n"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "#\n",
    "# Settings and placeholders\n",
    "#\n",
    "###########################################################\n",
    "\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_integer('neg_sample_size', 1, 'Negative sample size.')\n",
    "flags.DEFINE_float('learning_rate', 0.001, 'Initial learning rate.')\n",
    "flags.DEFINE_integer('epochs', 50, 'Number of epochs to train.')\n",
    "flags.DEFINE_integer('hidden1', 64, 'Number of units in hidden layer 1.')\n",
    "flags.DEFINE_integer('hidden2', 32, 'Number of units in hidden layer 2.')\n",
    "flags.DEFINE_float('weight_decay', 0, 'Weight for L2 loss on embedding matrix.')\n",
    "flags.DEFINE_float('dropout', 0.1, 'Dropout rate (1 - keep probability).')\n",
    "flags.DEFINE_float('max_margin', 0.1, 'Max margin parameter in hinge loss')\n",
    "flags.DEFINE_integer('batch_size', 512, 'minibatch size.')\n",
    "flags.DEFINE_boolean('bias', True, 'Bias term.')\n",
    "# Important -- Do not evaluate/print validation performance every iteration as it can take\n",
    "# substantial amount of time\n",
    "PRINT_PROGRESS_EVERY = 150\n",
    "\n",
    "print(\"Defining placeholders\")\n",
    "placeholders = construct_placeholders(edge_types)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create minibatch iterator\n",
      "Minibatch edge type: (0, 0, 0)\n",
      "Constructing test edges= 0000/143122\n",
      "Constructing test edges= 1000/143122\n",
      "Constructing test edges= 2000/143122\n",
      "Constructing test edges= 3000/143122\n",
      "Constructing test edges= 4000/143122\n",
      "Constructing test edges= 5000/143122\n",
      "Constructing test edges= 6000/143122\n",
      "Constructing test edges= 7000/143122\n",
      "Constructing test edges= 8000/143122\n",
      "Constructing test edges= 9000/143122\n",
      "Constructing test edges= 10000/143122\n",
      "Constructing test edges= 11000/143122\n",
      "Constructing test edges= 12000/143122\n",
      "Constructing test edges= 13000/143122\n",
      "Constructing test edges= 14000/143122\n",
      "Constructing test edges= 15000/143122\n",
      "Constructing test edges= 16000/143122\n",
      "Constructing test edges= 17000/143122\n",
      "Constructing test edges= 18000/143122\n",
      "Constructing test edges= 19000/143122\n",
      "Constructing test edges= 20000/143122\n",
      "Constructing test edges= 21000/143122\n",
      "Constructing test edges= 22000/143122\n",
      "Constructing test edges= 23000/143122\n",
      "Constructing test edges= 24000/143122\n",
      "Constructing test edges= 25000/143122\n",
      "Constructing test edges= 26000/143122\n",
      "Constructing test edges= 27000/143122\n",
      "Constructing test edges= 28000/143122\n",
      "Constructing test edges= 29000/143122\n",
      "Constructing test edges= 30000/143122\n",
      "Constructing test edges= 31000/143122\n",
      "Constructing test edges= 32000/143122\n",
      "Constructing test edges= 33000/143122\n",
      "Constructing test edges= 34000/143122\n",
      "Constructing test edges= 35000/143122\n",
      "Constructing test edges= 36000/143122\n",
      "Constructing test edges= 37000/143122\n",
      "Constructing test edges= 38000/143122\n",
      "Constructing test edges= 39000/143122\n",
      "Constructing test edges= 40000/143122\n",
      "Constructing test edges= 41000/143122\n",
      "Constructing test edges= 42000/143122\n",
      "Constructing test edges= 43000/143122\n",
      "Constructing test edges= 44000/143122\n",
      "Constructing test edges= 45000/143122\n",
      "Constructing test edges= 46000/143122\n",
      "Constructing test edges= 47000/143122\n",
      "Constructing test edges= 48000/143122\n",
      "Constructing test edges= 49000/143122\n",
      "Constructing test edges= 50000/143122\n",
      "Constructing test edges= 51000/143122\n",
      "Constructing test edges= 52000/143122\n",
      "Constructing test edges= 53000/143122\n",
      "Constructing test edges= 54000/143122\n",
      "Constructing test edges= 55000/143122\n",
      "Constructing test edges= 56000/143122\n",
      "Constructing test edges= 57000/143122\n",
      "Constructing test edges= 58000/143122\n",
      "Constructing test edges= 59000/143122\n",
      "Constructing test edges= 60000/143122\n",
      "Constructing test edges= 61000/143122\n",
      "Constructing test edges= 62000/143122\n",
      "Constructing test edges= 63000/143122\n",
      "Constructing test edges= 64000/143122\n",
      "Constructing test edges= 65000/143122\n",
      "Constructing test edges= 66000/143122\n",
      "Constructing test edges= 67000/143122\n",
      "Constructing test edges= 68000/143122\n",
      "Constructing test edges= 69000/143122\n",
      "Constructing test edges= 70000/143122\n",
      "Constructing test edges= 71000/143122\n",
      "Constructing test edges= 72000/143122\n",
      "Constructing test edges= 73000/143122\n",
      "Constructing test edges= 74000/143122\n",
      "Constructing test edges= 75000/143122\n",
      "Constructing test edges= 76000/143122\n",
      "Constructing test edges= 77000/143122\n",
      "Constructing test edges= 78000/143122\n",
      "Constructing test edges= 79000/143122\n",
      "Constructing test edges= 80000/143122\n",
      "Constructing test edges= 81000/143122\n",
      "Constructing test edges= 82000/143122\n",
      "Constructing test edges= 83000/143122\n",
      "Constructing test edges= 84000/143122\n",
      "Constructing test edges= 85000/143122\n",
      "Constructing test edges= 86000/143122\n",
      "Constructing test edges= 87000/143122\n",
      "Constructing test edges= 88000/143122\n",
      "Constructing test edges= 89000/143122\n",
      "Constructing test edges= 90000/143122\n",
      "Constructing test edges= 91000/143122\n",
      "Constructing test edges= 92000/143122\n",
      "Constructing test edges= 93000/143122\n",
      "Constructing test edges= 94000/143122\n",
      "Constructing test edges= 95000/143122\n",
      "Constructing test edges= 96000/143122\n",
      "Constructing test edges= 97000/143122\n",
      "Constructing test edges= 98000/143122\n",
      "Constructing test edges= 99000/143122\n",
      "Constructing test edges= 100000/143122\n",
      "Constructing test edges= 101000/143122\n",
      "Constructing test edges= 102000/143122\n",
      "Constructing test edges= 103000/143122\n",
      "Constructing test edges= 103000/143122\n",
      "Constructing test edges= 104000/143122\n",
      "Constructing test edges= 105000/143122\n",
      "Constructing test edges= 106000/143122\n",
      "Constructing test edges= 107000/143122\n",
      "Constructing test edges= 108000/143122\n",
      "Constructing test edges= 109000/143122\n",
      "Constructing test edges= 110000/143122\n",
      "Constructing test edges= 111000/143122\n",
      "Constructing test edges= 112000/143122\n",
      "Constructing test edges= 113000/143122\n",
      "Constructing test edges= 114000/143122\n",
      "Constructing test edges= 115000/143122\n",
      "Constructing test edges= 116000/143122\n",
      "Constructing test edges= 117000/143122\n",
      "Constructing test edges= 118000/143122\n",
      "Constructing test edges= 119000/143122\n",
      "Constructing test edges= 120000/143122\n",
      "Constructing test edges= 121000/143122\n",
      "Constructing test edges= 122000/143122\n",
      "Constructing test edges= 123000/143122\n",
      "Constructing test edges= 124000/143122\n",
      "Constructing test edges= 125000/143122\n",
      "Constructing test edges= 126000/143122\n",
      "Constructing test edges= 127000/143122\n",
      "Constructing test edges= 128000/143122\n",
      "Constructing test edges= 129000/143122\n",
      "Constructing test edges= 130000/143122\n",
      "Constructing test edges= 131000/143122\n",
      "Constructing test edges= 132000/143122\n",
      "Constructing test edges= 133000/143122\n",
      "Constructing test edges= 134000/143122\n",
      "Constructing test edges= 135000/143122\n",
      "Constructing test edges= 136000/143122\n",
      "Constructing test edges= 137000/143122\n",
      "Constructing test edges= 138000/143122\n",
      "Constructing test edges= 139000/143122\n",
      "Constructing test edges= 140000/143122\n",
      "Constructing test edges= 141000/143122\n",
      "Constructing test edges= 142000/143122\n",
      "Constructing test edges= 143000/143122\n",
      "Constructing val edges= 0000/143122\n",
      "Constructing val edges= 1000/143122\n",
      "Constructing val edges= 2000/143122\n",
      "Constructing val edges= 3000/143122\n",
      "Constructing val edges= 4000/143122\n",
      "Constructing val edges= 5000/143122\n",
      "Constructing val edges= 6000/143122\n",
      "Constructing val edges= 7000/143122\n",
      "Constructing val edges= 8000/143122\n",
      "Constructing val edges= 9000/143122\n",
      "Constructing val edges= 10000/143122\n",
      "Constructing val edges= 11000/143122\n",
      "Constructing val edges= 12000/143122\n",
      "Constructing val edges= 13000/143122\n",
      "Constructing val edges= 14000/143122\n",
      "Constructing val edges= 15000/143122\n",
      "Constructing val edges= 16000/143122\n",
      "Constructing val edges= 17000/143122\n",
      "Constructing val edges= 18000/143122\n",
      "Constructing val edges= 19000/143122\n",
      "Constructing val edges= 20000/143122\n",
      "Constructing val edges= 21000/143122\n",
      "Constructing val edges= 22000/143122\n",
      "Constructing val edges= 23000/143122\n",
      "Constructing val edges= 24000/143122\n",
      "Constructing val edges= 25000/143122\n",
      "Constructing val edges= 26000/143122\n",
      "Constructing val edges= 27000/143122\n",
      "Constructing val edges= 28000/143122\n",
      "Constructing val edges= 29000/143122\n",
      "Constructing val edges= 30000/143122\n",
      "Constructing val edges= 31000/143122\n",
      "Constructing val edges= 32000/143122\n",
      "Constructing val edges= 33000/143122\n",
      "Constructing val edges= 34000/143122\n",
      "Constructing val edges= 35000/143122\n",
      "Constructing val edges= 36000/143122\n",
      "Constructing val edges= 37000/143122\n",
      "Constructing val edges= 38000/143122\n",
      "Constructing val edges= 39000/143122\n",
      "Constructing val edges= 40000/143122\n",
      "Constructing val edges= 41000/143122\n",
      "Constructing val edges= 42000/143122\n",
      "Constructing val edges= 43000/143122\n",
      "Constructing val edges= 44000/143122\n",
      "Constructing val edges= 45000/143122\n",
      "Constructing val edges= 46000/143122\n",
      "Constructing val edges= 47000/143122\n",
      "Constructing val edges= 48000/143122\n",
      "Constructing val edges= 49000/143122\n",
      "Constructing val edges= 50000/143122\n",
      "Constructing val edges= 51000/143122\n",
      "Constructing val edges= 52000/143122\n",
      "Constructing val edges= 53000/143122\n",
      "Constructing val edges= 54000/143122\n",
      "Constructing val edges= 55000/143122\n",
      "Constructing val edges= 56000/143122\n",
      "Constructing val edges= 57000/143122\n",
      "Constructing val edges= 58000/143122\n",
      "Constructing val edges= 59000/143122\n",
      "Constructing val edges= 60000/143122\n",
      "Constructing val edges= 61000/143122\n",
      "Constructing val edges= 62000/143122\n",
      "Constructing val edges= 63000/143122\n",
      "Constructing val edges= 64000/143122\n",
      "Constructing val edges= 65000/143122\n",
      "Constructing val edges= 66000/143122\n",
      "Constructing val edges= 67000/143122\n",
      "Constructing val edges= 68000/143122\n",
      "Constructing val edges= 69000/143122\n"
     ]
    }
   ],
   "source": [
    "###########################################################\n",
    "#\n",
    "# Create minibatch iterator, model and optimizer\n",
    "#\n",
    "###########################################################\n",
    "\n",
    "print(\"Create minibatch iterator\")\n",
    "minibatch = EdgeMinibatchIterator(\n",
    "    adj_mats=adj_mats_orig,\n",
    "    feat=feat,\n",
    "    edge_types=edge_types,\n",
    "    batch_size=512,\n",
    "    val_test_size=val_test_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "fileObject = open(\"minibatch.pickle\",'rb')  \n",
    "minibatch = pickle.dump(minibatch, fileObject)  \n",
    "fileObject.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from decagon.deep.model import DecagonModel\n",
    "\n",
    "\n",
    "print(\"Create model\")\n",
    "model = DecagonModel(\n",
    "    placeholders=placeholders,\n",
    "    num_feat=num_feat,\n",
    "    nonzero_feat=nonzero_feat,\n",
    "    edge_types=edge_types,\n",
    "    decoders=edge_type2decoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Create optimizer\")\n",
    "with tf.name_scope('optimizer'):\n",
    "    opt = DecagonOptimizer(\n",
    "        embeddings=model.embeddings,\n",
    "        latent_inters=model.latent_inters,\n",
    "        latent_varies=model.latent_varies,\n",
    "        degrees=degrees,\n",
    "        edge_types=edge_types,\n",
    "        edge_type2dim=edge_type2dim,\n",
    "        placeholders=placeholders,\n",
    "        batch_size=512,\n",
    "        margin=0.1\n",
    "    )\n",
    "\n",
    "print(\"Initialize session\")\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "feed_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###########################################################\n",
    "#\n",
    "# Train model\n",
    "#\n",
    "###########################################################\n",
    "\n",
    "print(\"Train model\")\n",
    "for epoch in range(50):\n",
    "\n",
    "    minibatch.shuffle()\n",
    "    itr = 0\n",
    "    while not minibatch.end():\n",
    "        # Construct feed dictionary\n",
    "        feed_dict = minibatch.next_minibatch_feed_dict(placeholders=placeholders)\n",
    "        feed_dict = minibatch.update_feed_dict(\n",
    "            feed_dict=feed_dict,\n",
    "            dropout=0.1,\n",
    "            placeholders=placeholders)\n",
    "\n",
    "        t = time.time()\n",
    "\n",
    "        # Training step: run single weight update\n",
    "        outs = sess.run([opt.opt_op, opt.cost, opt.batch_edge_type_idx], feed_dict=feed_dict)\n",
    "        train_cost = outs[1]\n",
    "        batch_edge_type = outs[2]\n",
    "\n",
    "        if itr % PRINT_PROGRESS_EVERY == 0:\n",
    "            val_auc, val_auprc, val_apk = get_accuracy_scores(\n",
    "                minibatch.val_edges, minibatch.val_edges_false,\n",
    "                minibatch.idx2edge_type[minibatch.current_edge_type_idx])\n",
    "\n",
    "            print(\"Epoch:\", \"%04d\" % (epoch + 1), \"Iter:\", \"%04d\" % (itr + 1), \"Edge:\", \"%04d\" % batch_edge_type,\n",
    "                  \"train_loss=\", \"{:.5f}\".format(train_cost),\n",
    "                  \"val_roc=\", \"{:.5f}\".format(val_auc), \"val_auprc=\", \"{:.5f}\".format(val_auprc),\n",
    "                  \"val_apk=\", \"{:.5f}\".format(val_apk), \"time=\", \"{:.5f}\".format(time.time() - t))\n",
    "\n",
    "        itr += 1\n",
    "\n",
    "print(\"Optimization finished!\")\n",
    "\n",
    "for et in range(num_edge_types):\n",
    "    roc_score, auprc_score, apk_score = get_accuracy_scores(\n",
    "        minibatch.test_edges, minibatch.test_edges_false, minibatch.idx2edge_type[et])\n",
    "    print(\"Edge type=\", \"[%02d, %02d, %02d]\" % minibatch.idx2edge_type[et])\n",
    "    print(\"Edge type:\", \"%04d\" % et, \"Test AUROC score\", \"{:.5f}\".format(roc_score))\n",
    "    print(\"Edge type:\", \"%04d\" % et, \"Test AUPRC score\", \"{:.5f}\".format(auprc_score))\n",
    "    print(\"Edge type:\", \"%04d\" % et, \"Test AP@k score\", \"{:.5f}\".format(apk_score))\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python-with-Pixiedust_Spark-2.2",
   "language": "python",
   "name": "pythonwithpixiedustspark22"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
