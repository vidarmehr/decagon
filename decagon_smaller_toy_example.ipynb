{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ravanv/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n",
      "/Users/ravanv/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import sklearn.linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import statsmodels.api as sm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from operator import itemgetter\n",
    "from itertools import combinations\n",
    "import time\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "from sklearn import metrics\n",
    "\n",
    "from decagon.deep.optimizer import DecagonOptimizer\n",
    "from decagon.deep.model import DecagonModel\n",
    "from decagon.deep.minibatch import EdgeMinibatchIterator\n",
    "from decagon.utility import rank_metrics, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train on CPU (hide GPU) due to memory constraints\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"\"\n",
    "\n",
    "# Train on GPU\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = 'PCI_BUS_ID'\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "###########################################################\n",
    "#\n",
    "# Functions\n",
    "#\n",
    "###########################################################\n",
    "\n",
    "\n",
    "def get_accuracy_scores(edges_pos, edges_neg, edge_type):\n",
    "    feed_dict.update({placeholders['dropout']: 0})\n",
    "    feed_dict.update({placeholders['batch_edge_type_idx']: minibatch.edge_type2idx[edge_type]})\n",
    "    feed_dict.update({placeholders['batch_row_edge_type']: edge_type[0]})\n",
    "    feed_dict.update({placeholders['batch_col_edge_type']: edge_type[1]})\n",
    "    rec = sess.run(opt.predictions, feed_dict=feed_dict)\n",
    "\n",
    "    def sigmoid(x):\n",
    "        return 1. / (1 + np.exp(-x))\n",
    "\n",
    "    # Predict on test set of edges\n",
    "    preds = []\n",
    "    actual = []\n",
    "    predicted = []\n",
    "    edge_ind = 0\n",
    "    for u, v in edges_pos[edge_type[:2]][edge_type[2]]:\n",
    "        score = sigmoid(rec[u, v])\n",
    "        preds.append(score)\n",
    "        assert adj_mats_orig[edge_type[:2]][edge_type[2]][u,v] == 1, 'Problem 1'\n",
    "\n",
    "        actual.append(edge_ind)\n",
    "        predicted.append((score, edge_ind))\n",
    "        edge_ind += 1\n",
    "\n",
    "    preds_neg = []\n",
    "    for u, v in edges_neg[edge_type[:2]][edge_type[2]]:\n",
    "        score = sigmoid(rec[u, v])\n",
    "        preds_neg.append(score)\n",
    "        assert adj_mats_orig[edge_type[:2]][edge_type[2]][u,v] == 0, 'Problem 0'\n",
    "\n",
    "        predicted.append((score, edge_ind))\n",
    "        edge_ind += 1\n",
    "\n",
    "    preds_all = np.hstack([preds, preds_neg])\n",
    "    preds_all = np.nan_to_num(preds_all)\n",
    "    labels_all = np.hstack([np.ones(len(preds)), np.zeros(len(preds_neg))])\n",
    "    predicted = list(zip(*sorted(predicted, reverse=True, key=itemgetter(0))))[1]\n",
    "\n",
    "    roc_sc = metrics.roc_auc_score(labels_all, preds_all)\n",
    "    aupr_sc = metrics.average_precision_score(labels_all, preds_all)\n",
    "    apk_sc = rank_metrics.apk(actual, predicted, k=50)\n",
    "\n",
    "    return roc_sc, aupr_sc, apk_sc\n",
    "\n",
    "\n",
    "def construct_placeholders(edge_types):\n",
    "    placeholders = {\n",
    "        'batch': tf.placeholder(tf.int32, name='batch'),\n",
    "        'batch_edge_type_idx': tf.placeholder(tf.int32, shape=(), name='batch_edge_type_idx'),\n",
    "        'batch_row_edge_type': tf.placeholder(tf.int32, shape=(), name='batch_row_edge_type'),\n",
    "        'batch_col_edge_type': tf.placeholder(tf.int32, shape=(), name='batch_col_edge_type'),\n",
    "        'degrees': tf.placeholder(tf.int32),\n",
    "        'dropout': tf.placeholder_with_default(0., shape=()),\n",
    "    }\n",
    "    placeholders.update({\n",
    "        'adj_mats_%d,%d,%d' % (i, j, k): tf.sparse_placeholder(tf.float32)\n",
    "        for i, j in edge_types for k in range(edge_types[i,j])})\n",
    "    placeholders.update({\n",
    "        'feat_%d' % i: tf.sparse_placeholder(tf.float32)\n",
    "        for i, _ in edge_types})\n",
    "    return placeholders\n",
    "\n",
    "###########################################################\n",
    "#\n",
    "# Load and preprocess data (This is a dummy toy example!)\n",
    "#\n",
    "###########################################################\n",
    "\n",
    "####\n",
    "# The following code uses artificially generated and very small networks.\n",
    "# Expect less than excellent performance as these random networks do not have any interesting structure.\n",
    "# The purpose of main.py is to show how to use the code!\n",
    "#\n",
    "# All preprocessed datasets used in the drug combination study are at: http://snap.stanford.edu/decagon:\n",
    "# (1) Download datasets from http://snap.stanford.edu/decagon to your local machine.\n",
    "# (2) Replace dummy toy datasets used here with the actual datasets you just downloaded.\n",
    "# (3) Train & test the model.\n",
    "####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#val_test_size = 0.05\n",
    "#n_genes = 500\n",
    "#n_drugs = 400\n",
    "#n_drugdrug_rel_types = 3\n",
    "#gene_net = nx.planted_partition_graph(50, 10, 0.2, 0.05, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_test_size = 0.05\n",
    "n_genes = 60\n",
    "n_drugs = 10\n",
    "n_drugdrug_rel_types = 3\n",
    "gene_net = nx.planted_partition_graph(6, 10, 0.2, 0.05, seed=42)\n",
    "\n",
    "gene_adj = nx.adjacency_matrix(gene_net)\n",
    "gene_degrees = np.array(gene_adj.sum(axis=0)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#gene_drug_adj = sp.csr_matrix((10 * np.random.randn(n_genes, n_drugs) > 15).astype(int))\n",
    "#drug_gene_adj = gene_drug_adj.transpose(copy=True)\n",
    "\n",
    "#drug_drug_adj_list = []\n",
    "#tmp = np.dot(drug_gene_adj, gene_drug_adj)\n",
    "#for i in range(n_drugdrug_rel_types):\n",
    "#    mat = np.zeros((n_drugs, n_drugs))\n",
    "#    for d1, d2 in combinations(list(range(n_drugs)), 2):\n",
    "#        if tmp[d1, d2] == i + 4:\n",
    "#            mat[d1, d2] = mat[d2, d1] = 1.\n",
    "#    drug_drug_adj_list.append(sp.csr_matrix(mat))\n",
    "#drug_degrees_list = [np.array(drug_adj.sum(axis=0)).squeeze() for drug_adj in drug_drug_adj_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gene_drug_adj = sp.csr_matrix((10 * np.random.randn(n_genes, n_drugs) > 15).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drug_gene_adj = gene_drug_adj.transpose(copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 60)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_gene_adj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drug_drug_adj_list = []\n",
    "tmp = np.dot(drug_gene_adj, gene_drug_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(n_drugdrug_rel_types):\n",
    "    mat = np.zeros((n_drugs, n_drugs))\n",
    "    for d1, d2 in combinations(list(range(n_drugs)), 2):\n",
    "        if tmp[d1, d2] == i + 4:\n",
    "            mat[d1, d2] = mat[d2, d1] = 1.\n",
    "    drug_drug_adj_list.append(sp.csr_matrix(mat))\n",
    "    #print(mat)\n",
    "drug_degrees_list = [np.array(drug_adj.sum(axis=0)).squeeze() for drug_adj in drug_drug_adj_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adj_mats_orig = {\n",
    "    (0, 0): [gene_adj, gene_adj.transpose(copy=True)],\n",
    "    (0, 1): [gene_drug_adj],\n",
    "    (1, 0): [drug_gene_adj],\n",
    "    (1, 1): drug_drug_adj_list + [x.transpose(copy=True) for x in drug_drug_adj_list],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "degrees = {\n",
    "    0: [gene_degrees, gene_degrees],\n",
    "    1: drug_degrees_list + drug_degrees_list,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [array([ 7,  3,  4,  5,  8,  1,  3,  8,  7,  6,  3,  1,  4,  7,  4,  4,  4,\n",
       "          4,  5,  2,  6,  2,  6,  6,  2,  6,  4,  5,  2,  3,  3,  4,  3,  3,\n",
       "          8,  6,  2,  2,  6, 11,  4,  4,  6,  2,  8,  7,  6,  4,  2,  4,  5,\n",
       "          3,  3,  3,  3,  1,  3,  1,  6,  3], dtype=int64),\n",
       "  array([ 7,  3,  4,  5,  8,  1,  3,  8,  7,  6,  3,  1,  4,  7,  4,  4,  4,\n",
       "          4,  5,  2,  6,  2,  6,  6,  2,  6,  4,  5,  2,  3,  3,  4,  3,  3,\n",
       "          8,  6,  2,  2,  6, 11,  4,  4,  6,  2,  8,  7,  6,  4,  2,  4,  5,\n",
       "          3,  3,  3,  3,  1,  3,  1,  6,  3], dtype=int64)],\n",
       " 1: [array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]),\n",
       "  array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]),\n",
       "  array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]),\n",
       "  array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]),\n",
       "  array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]),\n",
       "  array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# featureless (genes)\n",
    "gene_feat = sp.identity(n_genes)\n",
    "gene_nonzero_feat, gene_num_feat = gene_feat.shape\n",
    "gene_feat = preprocessing.sparse_to_tuple(gene_feat.tocoo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0,  0],\n",
       "        [ 1,  1],\n",
       "        [ 2,  2],\n",
       "        [ 3,  3],\n",
       "        [ 4,  4],\n",
       "        [ 5,  5],\n",
       "        [ 6,  6],\n",
       "        [ 7,  7],\n",
       "        [ 8,  8],\n",
       "        [ 9,  9],\n",
       "        [10, 10],\n",
       "        [11, 11],\n",
       "        [12, 12],\n",
       "        [13, 13],\n",
       "        [14, 14],\n",
       "        [15, 15],\n",
       "        [16, 16],\n",
       "        [17, 17],\n",
       "        [18, 18],\n",
       "        [19, 19],\n",
       "        [20, 20],\n",
       "        [21, 21],\n",
       "        [22, 22],\n",
       "        [23, 23],\n",
       "        [24, 24],\n",
       "        [25, 25],\n",
       "        [26, 26],\n",
       "        [27, 27],\n",
       "        [28, 28],\n",
       "        [29, 29],\n",
       "        [30, 30],\n",
       "        [31, 31],\n",
       "        [32, 32],\n",
       "        [33, 33],\n",
       "        [34, 34],\n",
       "        [35, 35],\n",
       "        [36, 36],\n",
       "        [37, 37],\n",
       "        [38, 38],\n",
       "        [39, 39],\n",
       "        [40, 40],\n",
       "        [41, 41],\n",
       "        [42, 42],\n",
       "        [43, 43],\n",
       "        [44, 44],\n",
       "        [45, 45],\n",
       "        [46, 46],\n",
       "        [47, 47],\n",
       "        [48, 48],\n",
       "        [49, 49],\n",
       "        [50, 50],\n",
       "        [51, 51],\n",
       "        [52, 52],\n",
       "        [53, 53],\n",
       "        [54, 54],\n",
       "        [55, 55],\n",
       "        [56, 56],\n",
       "        [57, 57],\n",
       "        [58, 58],\n",
       "        [59, 59]], dtype=int32),\n",
       " array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]),\n",
       " (60, 60))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# features (drugs)\n",
    "drug_feat = sp.identity(n_drugs)\n",
    "drug_nonzero_feat, drug_num_feat = drug_feat.shape\n",
    "drug_feat = preprocessing.sparse_to_tuple(drug_feat.tocoo())\n",
    "\n",
    "# data representation\n",
    "num_feat = {\n",
    "    0: gene_num_feat,\n",
    "    1: drug_num_feat,\n",
    "}\n",
    "nonzero_feat = {\n",
    "    0: gene_nonzero_feat,\n",
    "    1: drug_nonzero_feat,\n",
    "}\n",
    "feat = {\n",
    "    0: gene_feat,\n",
    "    1: drug_feat,\n",
    "}\n",
    "\n",
    "edge_type2dim = {k: [adj.shape for adj in adjs] for k, adjs in adj_mats_orig.items()}\n",
    "edge_type2decoder = {\n",
    "    (0, 0): 'bilinear',\n",
    "    (0, 1): 'bilinear',\n",
    "    (1, 0): 'bilinear',\n",
    "    (1, 1): 'dedicom',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge types: 10\n"
     ]
    }
   ],
   "source": [
    "edge_types = {k: len(v) for k, v in adj_mats_orig.items()}\n",
    "num_edge_types = sum(edge_types.values())\n",
    "print(\"Edge types:\", \"%d\" % num_edge_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining placeholders\n"
     ]
    }
   ],
   "source": [
    "###########################################################\n",
    "#\n",
    "# Settings and placeholders\n",
    "#\n",
    "###########################################################\n",
    "\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_integer('neg_sample_size', 1, 'Negative sample size.')\n",
    "flags.DEFINE_float('learning_rate', 0.001, 'Initial learning rate.')\n",
    "flags.DEFINE_integer('epochs', 50, 'Number of epochs to train.')\n",
    "flags.DEFINE_integer('hidden1', 64, 'Number of units in hidden layer 1.')\n",
    "flags.DEFINE_integer('hidden2', 32, 'Number of units in hidden layer 2.')\n",
    "flags.DEFINE_float('weight_decay', 0, 'Weight for L2 loss on embedding matrix.')\n",
    "flags.DEFINE_float('dropout', 0.1, 'Dropout rate (1 - keep probability).')\n",
    "flags.DEFINE_float('max_margin', 0.1, 'Max margin parameter in hinge loss')\n",
    "flags.DEFINE_integer('batch_size', 512, 'minibatch size.')\n",
    "flags.DEFINE_boolean('bias', True, 'Bias term.')\n",
    "# Important -- Do not evaluate/print validation performance every iteration as it can take\n",
    "# substantial amount of time\n",
    "PRINT_PROGRESS_EVERY = 150\n",
    "\n",
    "print(\"Defining placeholders\")\n",
    "placeholders = construct_placeholders(edge_types)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create minibatch iterator\n",
      "Minibatch edge type: (0, 0, 0)\n",
      "Constructing test edges= 0000/0050\n",
      "Constructing val edges= 0000/0050\n",
      "Train edges= 0158\n",
      "Val edges= 0050\n",
      "Test edges= 0050\n",
      "Minibatch edge type: (0, 0, 1)\n",
      "Constructing test edges= 0000/0050\n",
      "Constructing val edges= 0000/0050\n",
      "Train edges= 0158\n",
      "Val edges= 0050\n",
      "Test edges= 0050\n",
      "Minibatch edge type: (0, 1, 0)\n",
      "Constructing val edges= 0000/0039\n",
      "Train edges= 0000\n",
      "Val edges= 0039\n",
      "Test edges= 0000\n",
      "Minibatch edge type: (1, 0, 0)\n",
      "Constructing val edges= 0000/0039\n",
      "Train edges= 0000\n",
      "Val edges= 0039\n",
      "Test edges= 0000\n",
      "Minibatch edge type: (1, 1, 0)\n",
      "Train edges= 0000\n",
      "Val edges= 0000\n",
      "Test edges= 0000\n",
      "Minibatch edge type: (1, 1, 1)\n",
      "Train edges= 0000\n",
      "Val edges= 0000\n",
      "Test edges= 0000\n",
      "Minibatch edge type: (1, 1, 2)\n",
      "Train edges= 0000\n",
      "Val edges= 0000\n",
      "Test edges= 0000\n",
      "Minibatch edge type: (1, 1, 3)\n",
      "Train edges= 0000\n",
      "Val edges= 0000\n",
      "Test edges= 0000\n",
      "Minibatch edge type: (1, 1, 4)\n",
      "Train edges= 0000\n",
      "Val edges= 0000\n",
      "Test edges= 0000\n",
      "Minibatch edge type: (1, 1, 5)\n",
      "Train edges= 0000\n",
      "Val edges= 0000\n",
      "Test edges= 0000\n",
      "Create model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ravanv/Desktop/Decagon/decagon-master/decagon/deep/minibatch.py:67: RuntimeWarning: divide by zero encountered in power\n",
      "  rowdegree_mat_inv = sp.diags(np.nan_to_num(np.power(rowsum, -0.5)).flatten())\n",
      "/Users/ravanv/Desktop/Decagon/decagon-master/decagon/deep/minibatch.py:68: RuntimeWarning: divide by zero encountered in power\n",
      "  coldegree_mat_inv = sp.diags(np.nan_to_num(np.power(colsum, -0.5)).flatten())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create optimizer\n",
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n",
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ravanv/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize session\n"
     ]
    }
   ],
   "source": [
    "###########################################################\n",
    "#\n",
    "# Create minibatch iterator, model and optimizer\n",
    "#\n",
    "###########################################################\n",
    "\n",
    "print(\"Create minibatch iterator\")\n",
    "minibatch = EdgeMinibatchIterator(\n",
    "    adj_mats=adj_mats_orig,\n",
    "    feat=feat,\n",
    "    edge_types=edge_types,\n",
    "    batch_size=FLAGS.batch_size,\n",
    "    val_test_size=val_test_size\n",
    ")\n",
    "\n",
    "print(\"Create model\")\n",
    "model = DecagonModel(\n",
    "    placeholders=placeholders,\n",
    "    num_feat=num_feat,\n",
    "    nonzero_feat=nonzero_feat,\n",
    "    edge_types=edge_types,\n",
    "    decoders=edge_type2decoder,\n",
    ")\n",
    "\n",
    "print(\"Create optimizer\")\n",
    "with tf.name_scope('optimizer'):\n",
    "    opt = DecagonOptimizer(\n",
    "        embeddings=model.embeddings,\n",
    "        latent_inters=model.latent_inters,\n",
    "        latent_varies=model.latent_varies,\n",
    "        degrees=degrees,\n",
    "        edge_types=edge_types,\n",
    "        edge_type2dim=edge_type2dim,\n",
    "        placeholders=placeholders,\n",
    "        batch_size=FLAGS.batch_size,\n",
    "        margin=FLAGS.max_margin\n",
    "    )\n",
    "\n",
    "print(\"Initialize session\")\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "feed_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model\n",
      "iteration: 0\n"
     ]
    }
   ],
   "source": [
    "###########################################################\n",
    "#\n",
    "# Train model\n",
    "#\n",
    "###########################################################\n",
    "\n",
    "print(\"Train model\")\n",
    "for epoch in range(FLAGS.epochs):\n",
    "\n",
    "    minibatch.shuffle()\n",
    "    itr = 0\n",
    "    while not minibatch.end():\n",
    "        print(\"iteration:\", itr)\n",
    "        # Construct feed dictionary\n",
    "        feed_dict = minibatch.next_minibatch_feed_dict(placeholders=placeholders)\n",
    "        feed_dict = minibatch.update_feed_dict(\n",
    "            feed_dict=feed_dict,\n",
    "            dropout=FLAGS.dropout,\n",
    "            placeholders=placeholders)\n",
    "\n",
    "        t = time.time()\n",
    "\n",
    "        # Training step: run single weight update\n",
    "        outs = sess.run([opt.opt_op, opt.cost, opt.batch_edge_type_idx], feed_dict=feed_dict)\n",
    "        train_cost = outs[1]\n",
    "        batch_edge_type = outs[2]\n",
    "\n",
    "        if itr % PRINT_PROGRESS_EVERY == 0:\n",
    "            val_auc, val_auprc, val_apk = get_accuracy_scores(\n",
    "                minibatch.val_edges, minibatch.val_edges_false,\n",
    "                minibatch.idx2edge_type[minibatch.current_edge_type_idx])\n",
    "\n",
    "            print(\"Epoch:\", \"%04d\" % (epoch + 1), \"Iter:\", \"%04d\" % (itr + 1), \"Edge:\", \"%04d\" % batch_edge_type,\n",
    "                  \"train_loss=\", \"{:.5f}\".format(train_cost),\n",
    "                  \"val_roc=\", \"{:.5f}\".format(val_auc), \"val_auprc=\", \"{:.5f}\".format(val_auprc),\n",
    "                  \"val_apk=\", \"{:.5f}\".format(val_apk), \"time=\", \"{:.5f}\".format(time.time() - t))\n",
    "\n",
    "        itr += 1\n",
    "\n",
    "print(\"Optimization finished!\")\n",
    "\n",
    "for et in range(num_edge_types):\n",
    "    roc_score, auprc_score, apk_score = get_accuracy_scores(\n",
    "        minibatch.test_edges, minibatch.test_edges_false, minibatch.idx2edge_type[et])\n",
    "    print(\"Edge type=\", \"[%02d, %02d, %02d]\" % minibatch.idx2edge_type[et])\n",
    "    print(\"Edge type:\", \"%04d\" % et, \"Test AUROC score\", \"{:.5f}\".format(roc_score))\n",
    "    print(\"Edge type:\", \"%04d\" % et, \"Test AUPRC score\", \"{:.5f}\".format(auprc_score))\n",
    "    print(\"Edge type:\", \"%04d\" % et, \"Test AP@k score\", \"{:.5f}\".format(apk_score))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
